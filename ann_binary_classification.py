# -*- coding: utf-8 -*-
"""ANN Binary Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PR7wnBBVILEJFtdIp13Myw0rx5Vb8lpK
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

df=pd.read_csv('data.csv')
pd.set_option('display.max_rows',None)
pd.set_option('display.max_columns',None)

df.head(2)

df.shape

sns.countplot(df['diagnosis'])
B,M=df['diagnosis'].value_counts()
print('Benign: ',B)
print('Malignant: ',M)
plt.show()

del(df['Unnamed: 32'])

df.shape

df.head(2)

df.isnull().sum()

sns.heatmap(df.isnull())

X=df.iloc[:,2:].values
X

y=df.iloc[:,1].values

y

from sklearn.preprocessing import OneHotEncoder,LabelEncoder

le=LabelEncoder()

y=le.fit_transform(y)

y

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

X_train.shape,X_test.shape,y_train.shape,y_test.shape

#Feature Scaling
from sklearn.preprocessing import MinMaxScaler,StandardScaler

sc=StandardScaler()

X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

X_train

X_test

import keras

from keras.models import Sequential

from keras.layers import Dense

# Adding the Input & First hidden Layers
classifier=Sequential()
classifier.add(Dense(16,kernel_initializer='uniform',activation='relu',input_dim=30))
# Adding Second Hidden Layer
classifier.add(Dense(16,kernel_initializer='uniform',activation='relu'))
# Output Layer
classifier.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))

classifier.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])

classifier.fit(X_train,y_train,batch_size=100,epochs=150)

# Predicting the Test Set results
y_pred=classifier.predict(X_test)
y_pred=(y_pred>0.5)

# Making the confusion metrics
from sklearn.metrics import confusion_matrix,accuracy_score,mean_absolute_error,mean_squared_error,classification_report

cm=confusion_matrix(y_test,y_pred)

sns.heatmap(cm,annot=True)

